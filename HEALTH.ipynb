{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34d66f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common subjects: [1, 2, 4, 5, 6, 7, 8, 10, 13, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 27, 31, 32, 33, 34, 35, 37, 39, 42]\n",
      "Aligned df1 shape: (171, 22)\n",
      "Aligned df2 shape: (171, 25)\n",
      "Epoch 0: Loss=1.0996, Silhouette=0.7036\n",
      "Epoch 50: Loss=0.3038, Silhouette=0.3899\n",
      "Epoch 100: Loss=0.2171, Silhouette=0.4065\n",
      "Epoch 150: Loss=0.1057, Silhouette=0.4740\n",
      "Epoch 200: Loss=0.0641, Silhouette=0.4193\n",
      "Epoch 250: Loss=0.0597, Silhouette=0.4308\n",
      "Epoch 300: Loss=0.0593, Silhouette=0.4393\n",
      "Epoch 350: Loss=0.0592, Silhouette=0.4651\n",
      "Epoch 400: Loss=0.0592, Silhouette=0.4310\n",
      "Epoch 450: Loss=0.0592, Silhouette=0.4379\n",
      "Epoch 500: Loss=0.0592, Silhouette=0.4379\n",
      "Epoch 550: Loss=0.0592, Silhouette=0.4307\n",
      "SHAP: Detected 3D output, selecting class 1 contributions.\n",
      "âœ… All steps completed. Results saved in: /Volumes/SP_SAGHAR/Documents/University/Articles/Conference/5- ICBME/2/result\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_samples, accuracy_score, f1_score, roc_auc_score\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import shap\n",
    "import geoopt\n",
    "import torch\n",
    "\n",
    "# ----------------------\n",
    "# Configuration\n",
    "# ----------------------\n",
    "output_dir = \"result\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "file1 = \"data\"\n",
    "file2 = \"data\"\n",
    "\n",
    "# ----------------------\n",
    "# Load Datasets\n",
    "# ----------------------\n",
    "df1 = pd.read_csv(file1)\n",
    "df2 = pd.read_csv(file2)\n",
    "\n",
    "if \"name\" in df2.columns:\n",
    "    df2[\"subject#\"] = df2[\"name\"].str.extract(r'_S(\\d+)_').astype(int)[0]\n",
    "\n",
    "subjects1 = set(df1[\"subject#\"].unique())\n",
    "subjects2 = set(df2[\"subject#\"].unique())\n",
    "common_subjects = sorted(subjects1.intersection(subjects2))\n",
    "print(\"Common subjects:\", common_subjects)\n",
    "\n",
    "# ----------------------\n",
    "# Align rows per subject\n",
    "# ----------------------\n",
    "aligned_rows_1 = []\n",
    "aligned_rows_2 = []\n",
    "\n",
    "for s in common_subjects:\n",
    "    rows1 = df1[df1[\"subject#\"] == s]\n",
    "    rows2 = df2[df2[\"subject#\"] == s]\n",
    "    n = min(len(rows1), len(rows2))\n",
    "    aligned_rows_1.append(rows1.iloc[:n, :])\n",
    "    aligned_rows_2.append(rows2.iloc[:n, :])\n",
    "\n",
    "df1_aligned = pd.concat(aligned_rows_1).reset_index(drop=True)\n",
    "df2_aligned = pd.concat(aligned_rows_2).reset_index(drop=True)\n",
    "\n",
    "print(\"Aligned df1 shape:\", df1_aligned.shape)\n",
    "print(\"Aligned df2 shape:\", df2_aligned.shape)\n",
    "\n",
    "# ----------------------\n",
    "# Preprocessing\n",
    "def preprocess(df, drop_cols=[]):\n",
    "    df = df.drop(columns=drop_cols, errors=\"ignore\")\n",
    "    df_numeric = df.apply(pd.to_numeric, errors=\"coerce\").fillna(0)\n",
    "    scaler = StandardScaler()\n",
    "    scaled = scaler.fit_transform(df_numeric)\n",
    "    return scaled, df_numeric.columns.tolist()\n",
    "\n",
    "X1, cols1 = preprocess(df1_aligned, drop_cols=[\"subject#\", \"test_time\"])\n",
    "X2, cols2 = preprocess(df2_aligned, drop_cols=[\"subject#\", \"name\", \"status\"])\n",
    "\n",
    "if \"status\" in df2_aligned.columns:\n",
    "    y = df2_aligned[\"status\"].values\n",
    "    compute_classification_metrics = True\n",
    "else:\n",
    "    y = None\n",
    "    compute_classification_metrics = False\n",
    "\n",
    "# ----------------------\n",
    "# Similarity Matrix\n",
    "similarity_matrix = cosine_similarity(X1)\n",
    "\n",
    "# ----------------------\n",
    "# Graph Construction\n",
    "k = 10\n",
    "G = nx.Graph()\n",
    "for i in range(similarity_matrix.shape[0]):\n",
    "    indices = np.argsort(-similarity_matrix[i])[1:k+1]\n",
    "    for j in indices:\n",
    "        G.add_edge(i, j, weight=similarity_matrix[i, j])\n",
    "\n",
    "# ----------------------\n",
    "# Hyperbolic Embedding\n",
    "torch.manual_seed(0)\n",
    "manifold = geoopt.PoincareBall()\n",
    "embedding = torch.nn.Parameter(torch.randn(X1.shape[0], 2) * 1e-2)\n",
    "optimizer = torch.optim.Adam([embedding], lr=1e-2)\n",
    "\n",
    "n_epochs = 600\n",
    "losses, rmse_scores, mae_scores, silhouette_scores = [], [], [], []\n",
    "accuracy_scores, f1_scores, roc_auc_scores = [], [], []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    dist = manifold.dist(embedding.unsqueeze(0), embedding.unsqueeze(1))\n",
    "    target = torch.from_numpy(1 - similarity_matrix).float()\n",
    "    loss = torch.mean((dist - target) ** 2)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    with torch.no_grad():\n",
    "        embedding.copy_(manifold.projx(embedding))\n",
    "\n",
    "    losses.append(loss.item())\n",
    "    rmse_scores.append(torch.sqrt(torch.mean((dist - target)**2)).item())\n",
    "    mae_scores.append(torch.mean(torch.abs(dist - target)).item())\n",
    "\n",
    "    with torch.no_grad():\n",
    "        emb_np = embedding.detach().cpu().numpy()\n",
    "        cluster = AgglomerativeClustering(n_clusters=4).fit(emb_np)\n",
    "        sil = silhouette_samples(emb_np, cluster.labels_).mean()\n",
    "        silhouette_scores.append(sil)\n",
    "\n",
    "        if compute_classification_metrics:\n",
    "            rf = RandomForestClassifier(n_estimators=50, random_state=42)\n",
    "            rf.fit(emb_np, y)\n",
    "            y_pred = rf.predict(emb_np)\n",
    "            y_prob = rf.predict_proba(emb_np)[:,1]\n",
    "            if len(np.unique(y_pred)) < 2:\n",
    "                acc, f1, auc = np.nan, np.nan, np.nan\n",
    "            else:\n",
    "                acc = accuracy_score(y, y_pred)\n",
    "                f1 = f1_score(y, y_pred)\n",
    "                auc = roc_auc_score(y, y_prob)\n",
    "            accuracy_scores.append(acc)\n",
    "            f1_scores.append(f1)\n",
    "            roc_auc_scores.append(auc)\n",
    "        else:\n",
    "            accuracy_scores.append(np.nan)\n",
    "            f1_scores.append(np.nan)\n",
    "            roc_auc_scores.append(np.nan)\n",
    "\n",
    "    if epoch % 50 == 0:\n",
    "        print(f\"Epoch {epoch}: Loss={loss.item():.4f}, Silhouette={sil:.4f}\")\n",
    "\n",
    "embedding_np = embedding.detach().cpu().numpy()\n",
    "labels = cluster.labels_\n",
    "\n",
    "# ----------------------\n",
    "# Save Embedding Results\n",
    "df_embedding = pd.DataFrame(embedding_np, columns=[\"Dim1\", \"Dim2\"])\n",
    "df_embedding[\"Cluster\"] = labels\n",
    "df_embedding[\"SubjectID\"] = df1_aligned[\"subject#\"].values\n",
    "df_embedding.to_excel(os.path.join(output_dir, \"embedding_clusters.xlsx\"), index=False)\n",
    "\n",
    "# ----------------------\n",
    "# Plotting\n",
    "def save_fig(name):\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, name))\n",
    "    plt.close()\n",
    "\n",
    "# 1. Metrics Over Epochs\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(losses, label=\"Loss\")\n",
    "plt.plot(rmse_scores, label=\"RMSE\")\n",
    "plt.plot(mae_scores, label=\"MAE\")\n",
    "plt.plot(silhouette_scores, label=\"Silhouette\")\n",
    "plt.legend()\n",
    "plt.title(\"Embedding and Classification Metrics Over Epochs\")\n",
    "save_fig(\"metrics_over_epochs.png\")\n",
    "\n",
    "# 2. Embedding Scatter\n",
    "plt.figure()\n",
    "sns.scatterplot(x=embedding_np[:,0], y=embedding_np[:,1], hue=labels, palette=\"tab10\")\n",
    "plt.title(\"Embedding Scatter\")\n",
    "save_fig(\"embedding_scatter.png\")\n",
    "\n",
    "# 3. Distance Distribution\n",
    "dists = dist.detach().numpy().flatten()\n",
    "plt.figure()\n",
    "plt.hist(dists, bins=50)\n",
    "plt.title(\"Distance Histogram\")\n",
    "save_fig(\"distance_histogram.png\")\n",
    "\n",
    "# 4. Silhouette Distribution\n",
    "sil_vals = silhouette_samples(embedding_np, labels)\n",
    "plt.figure()\n",
    "plt.hist(sil_vals, bins=20)\n",
    "plt.title(\"Silhouette Histogram\")\n",
    "save_fig(\"silhouette_histogram.png\")\n",
    "\n",
    "# 5. Similarity Heatmap\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(similarity_matrix[:100,:100], cmap=\"viridis\")\n",
    "plt.title(\"Similarity Heatmap (First 100)\")\n",
    "save_fig(\"similarity_heatmap.png\")\n",
    "\n",
    "# 6. Graph Degree Distribution\n",
    "degrees = [d for n,d in G.degree()]\n",
    "plt.figure()\n",
    "plt.hist(degrees, bins=range(1,max(degrees)+2))\n",
    "plt.title(\"Graph Degree Distribution\")\n",
    "save_fig(\"degree_distribution.png\")\n",
    "\n",
    "# 7. t-SNE\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "tsne_proj = tsne.fit_transform(X1)\n",
    "plt.figure()\n",
    "sns.scatterplot(x=tsne_proj[:,0], y=tsne_proj[:,1], hue=labels, palette=\"tab10\")\n",
    "plt.title(\"t-SNE Projection\")\n",
    "save_fig(\"tsne_projection.png\")\n",
    "\n",
    "# 8. Dendrogram\n",
    "linked = linkage(embedding_np, method=\"ward\")\n",
    "plt.figure(figsize=(12,5))\n",
    "dendrogram(linked)\n",
    "plt.title(\"Dendrogram\")\n",
    "save_fig(\"dendrogram.png\")\n",
    "\n",
    "# 9. Graph Visualization with Legend\n",
    "plt.figure(figsize=(8,8))\n",
    "pos = nx.spring_layout(G)\n",
    "\n",
    "# prepare unique labels\n",
    "unique_labels = np.unique(labels)\n",
    "cmap = plt.get_cmap(\"tab10\")\n",
    "\n",
    "# draw edges\n",
    "nx.draw_networkx_edges(G, pos, alpha=0.1)\n",
    "\n",
    "# draw nodes per cluster\n",
    "for lab in unique_labels:\n",
    "    idx = np.where(labels == lab)[0]\n",
    "    nx.draw_networkx_nodes(\n",
    "        G, pos,\n",
    "        nodelist=idx,\n",
    "        node_size=20,\n",
    "        node_color=[cmap(lab)],\n",
    "        label=f\"Cluster {lab}\"\n",
    "    )\n",
    "\n",
    "plt.title(\"Graph Visualization with Clusters\")\n",
    "plt.legend(title=\"Clusters\", loc=\"best\")\n",
    "save_fig(\"graph_visualization.png\")\n",
    "\n",
    "# 10. Correlation Heatmap\n",
    "corr = pd.DataFrame(X1, columns=cols1).corr()\n",
    "plt.figure(figsize=(15,15))\n",
    "sns.heatmap(corr, cmap=\"coolwarm\")\n",
    "plt.title(\"Feature Correlation Heatmap\")\n",
    "save_fig(\"correlation_heatmap.png\")\n",
    "\n",
    "def plot_poincare_disk(embeddings, labels, path):\n",
    "    fig, ax = plt.subplots(figsize=(6,6))\n",
    "    circle = plt.Circle((0,0), 1, fill=False, color=\"black\")\n",
    "    ax.add_artist(circle)\n",
    "\n",
    "    unique_labels = np.unique(labels)\n",
    "    cmap = plt.get_cmap(\"tab10\")\n",
    "\n",
    "   \n",
    "    for lab in unique_labels:\n",
    "        idx = np.where(labels == lab)[0]\n",
    "        ax.scatter(\n",
    "            embeddings[idx,0],\n",
    "            embeddings[idx,1],\n",
    "            c=[cmap(lab)],\n",
    "            s=30,\n",
    "            edgecolor=\"k\",\n",
    "            label=f\"Cluster {lab}\"\n",
    "        )\n",
    "\n",
    "    ax.set_xlim(-1.05,1.05)\n",
    "    ax.set_ylim(-1.05,1.05)\n",
    "    ax.set_aspect(\"equal\")\n",
    "    ax.axis(\"off\")\n",
    "    plt.title(\"PoincarÃ© Disk Embedding\")\n",
    "    plt.legend(title=\"Clusters\", loc=\"best\")\n",
    "    save_fig(path)\n",
    "\n",
    "\n",
    "# 12. SHAP Plot\n",
    "rf_final = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_final.fit(X2, y)\n",
    "explainer = shap.TreeExplainer(rf_final)\n",
    "shap_values = explainer.shap_values(X2)\n",
    "\n",
    "# Handle proper slicing\n",
    "if len(shap_values.shape) == 3:\n",
    "    print(\"SHAP: Detected 3D output, selecting class 1 contributions.\")\n",
    "    shap_values_class1 = shap_values[:,:,1]\n",
    "else:\n",
    "    shap_values_class1 = shap_values\n",
    "\n",
    "# Safety check\n",
    "if shap_values_class1.shape[1] > X2.shape[1]:\n",
    "    print(\"SHAP: Detected extra column, slicing to match features...\")\n",
    "    shap_values_class1 = shap_values_class1[:, :-1]\n",
    "\n",
    "shap.summary_plot(\n",
    "    shap_values_class1,\n",
    "    pd.DataFrame(X2, columns=cols2),\n",
    "    max_display=X2.shape[1],\n",
    "    show=False\n",
    ")\n",
    "save_fig(\"shap_summary.png\")\n",
    "\n",
    "\n",
    "print(\"âœ… All steps completed. Results saved in:\", output_dir)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
